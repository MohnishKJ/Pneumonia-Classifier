{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f24c0c-2e7f-401c-a6a5-100968adb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ee46a8-5d3c-474b-96fb-ad5a14471fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global parameters\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10  # Increased number of epochs for better training\n",
    "DATA_DIR = \"C:/Users/User/OneDrive/pneumonia-detection/chest_xray/chest_xray\"\n",
    "MODEL_SAVE_PATH = \"C:/Users/User/OneDrive/pneumonia-detection/best_model.keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab244372-0ea9-4f71-b194-75a87d79e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Preprocessing & Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.4,\n",
    "                                   height_shift_range=0.4,\n",
    "                                   shear_range=0.2,\n",
    "                                   fill_mode=\"nearest\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(os.path.join(DATA_DIR, 'train'),\n",
    "                                                    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(os.path.join(DATA_DIR, 'val'),\n",
    "                                                   target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(os.path.join(DATA_DIR, 'test'),\n",
    "                                                  target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b007b9-9c9a-4c76-8e8d-8e755cf04380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the VGG19-based Model\n",
    "base_model = VGG19(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Freezing base model layers\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Reduced layer sizes for optimized performance\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "637e2578-5743-4de0-8db5-a5901a4e13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for monitoring the model's performance\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e447dbd-fa33-4bce-9f45-ed580cd92515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6904 - loss: 0.6001\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87500, saving model to C:/Users/User/OneDrive/pneumonia-detection/best_model.keras\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 4s/step - accuracy: 0.6907 - loss: 0.5996 - val_accuracy: 0.8750 - val_loss: 0.4579 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7986 - loss: 0.4365\n",
      "Epoch 2: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 4s/step - accuracy: 0.7986 - loss: 0.4364 - val_accuracy: 0.7500 - val_loss: 0.5071 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8047 - loss: 0.4095\n",
      "Epoch 3: val_accuracy did not improve from 0.87500\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 3s/step - accuracy: 0.8048 - loss: 0.4095 - val_accuracy: 0.6250 - val_loss: 0.5745 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8125 - loss: 0.3935\n",
      "Epoch 4: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 3s/step - accuracy: 0.8126 - loss: 0.3934 - val_accuracy: 0.7500 - val_loss: 0.5076 - learning_rate: 5.0000e-05\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[checkpoint, early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcd26c08-c8ab-4420-81f2-9623cf6315fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - accuracy: 0.7470 - loss: 0.5579\n",
      "Test Accuracy: 75.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save final model if it's the best one\n",
    "if not os.path.exists('models/'):\n",
    "    os.makedirs('models/')\n",
    "model.save('models/final_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
